'''
streamlit==1.30.0
joblib==1.4.2
numpy==1.26.4
pandas==2.2.2
matplotlib==3.8.0
scikit-learn==1.5.1
'''
import streamlit as st
import streamlit.components.v1
import joblib
import numpy as np
print(np.__version__)
import pandas as pd
print(pd.__version__)
import shap
import matplotlib.pyplot as plt
import tempfile
import os

# åŠ è½½ä¿å­˜çš„éšæœºæ£®æ—æ¨¡å‹
model = joblib.load('GNB_RFã€final_modelã€‘.pkl')
# åŠ è½½ä¿å­˜çš„StandardScaler
scaler = joblib.load('feature_scaler.pkl')
# ç‰¹å¾èŒƒå›´å®šä¹‰ï¼ˆæ ¹æ®æä¾›çš„ç‰¹å¾èŒƒå›´å’Œæ•°æ®ç±»å‹ï¼‰
feature_ranges = {
    "CHI3L1": {"type": "numerical", "min": 0.000, "max": 2000.000, "default": 79.000},
    "ALP": {"type": "numerical", "min": 0.000, "max": 1000.000, "default": 24.555},
    "Fibrinogen": {"type": "numerical", "min": 0.000, "max": 10.000, "default": 4.000},
    "Chlid": {"type": "numerical", "min": 0, "max": 10, "default": 6},
    "PIVAK_2": {"type": "numerical", "min": 0.000, "max": 100000.000, "default": 40.000},
    "Fer": {"type": "numerical", "min": 0.000, "max": 10000.000, "default": 400.000},
}

# Streamlit ç•Œé¢
st.title("Prediction Model with SHAP Visualization")

# åŠ¨æ€ç”Ÿæˆè¾“å…¥é¡¹
st.header("Enter the following feature values:")
feature_values = []
for feature, properties in feature_ranges.items():
    if properties["type"] == "numerical":
        value = st.number_input(
            label=f"{feature} ({properties['min']} - {properties['max']})",
            min_value=float(properties["min"]),
            max_value=float(properties["max"]),
            value=float(properties["default"]),
        )
    elif properties["type"] == "categorical":
        value = st.selectbox(
            label=f"{feature} (Select a value)",
            options=properties["options"],
        )
    feature_values.append(value)

# è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
features_raw = np.array([feature_values])

# é¢„æµ‹ä¸ SHAP å¯è§†åŒ–
if st.button("Predict"):
    # # æ˜¾ç¤ºè¾“å…¥çš„åŸå§‹æ•°æ®
    # st.subheader("è¾“å…¥æ•°æ®å¤„ç†è¿‡ç¨‹:")
    # st.write("**åŸå§‹è¾“å…¥æ•°æ®:**")
    # raw_data_df = pd.DataFrame([feature_values], columns=feature_ranges.keys())
    # st.dataframe(raw_data_df)
    
    # å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
    features_scaled = scaler.transform(features_raw)
    
    # # æ˜¾ç¤ºæ ‡å‡†åŒ–åçš„æ•°æ®
    # st.write("**æ ‡å‡†åŒ–åçš„æ•°æ®:**")
    # scaled_data_df = pd.DataFrame(features_scaled, columns=feature_ranges.keys())
    # st.dataframe(scaled_data_df)
    
    # æ¨¡å‹é¢„æµ‹ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–åçš„æ•°æ®ï¼‰
    predicted_class = model.predict(features_scaled)[0]
    predicted_proba = model.predict_proba(features_scaled)[0]

    # æå–å¤±ä»£å¿å‘ç”Ÿçš„æ¦‚ç‡ï¼ˆé€šå¸¸æ˜¯ç±»åˆ«1çš„æ¦‚ç‡ï¼‰
    # å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼šç±»åˆ«0=æ— å¤±ä»£å¿ï¼Œç±»åˆ«1=æœ‰å¤±ä»£å¿
    decompensation_probability = predicted_proba[1] * 100  # å¤±ä»£å¿å‘ç”Ÿçš„æ¦‚ç‡
    
    # ä½¿ç”¨å¤±ä»£å¿å‘ç”Ÿçš„æ¦‚ç‡ä½œä¸ºä¸»è¦æ˜¾ç¤ºç»“æœ
    probability = decompensation_probability

    # æ˜¾ç¤ºé¢„æµ‹ç»“æœï¼Œä½¿ç”¨ Matplotlib æ¸²æŸ“æŒ‡å®šå­—ä½“
    text = f"Predicted possibility of Postoperative Decompensation after TACE is {probability:.2f}%"
    fig, ax = plt.subplots(figsize=(8, 1))
    ax.text(
        0.5, 0.5, text,
        fontsize=16,
        ha='center', va='center',
        fontname='Times New Roman',
        transform=ax.transAxes
    )
    ax.axis('off')
    plt.savefig("prediction_text.png", bbox_inches='tight', dpi=300)
    st.image("prediction_text.png")

    # è®¡ç®— SHAP å€¼ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–åçš„æ•°æ®ï¼‰
    features_df_scaled = pd.DataFrame(features_scaled, columns=feature_ranges.keys())
    
    # ä¸ºå †å æ¨¡å‹åˆ›å»ºä¸€ä¸ªå¯è°ƒç”¨çš„é¢„æµ‹å‡½æ•°
    # è¿”å›å¤±ä»£å¿ç±»åˆ«ï¼ˆç±»åˆ«1ï¼‰çš„æ¦‚ç‡
    def model_predict(X):
        if hasattr(model, 'predict_proba'):
            proba = model.predict_proba(X)
            return proba[:, 1]  # åªè¿”å›å¤±ä»£å¿ç±»åˆ«çš„æ¦‚ç‡
        else:
            return model.predict(X)
    
    # ä½¿ç”¨KernelExplainerå¤„ç†å †å æ¨¡å‹
    # åˆ›å»ºèƒŒæ™¯æ•°æ®é›† - ä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®çš„å‡å€¼ä½œä¸ºåŸºå‡†
    # æ³¨æ„ï¼šfeatures_scaledæ˜¯1Dæ•°ç»„ï¼Œéœ€è¦reshapeä¸º2D
    current_sample_2d = features_scaled.reshape(1, -1)
    background_data = np.zeros_like(current_sample_2d)  # åˆ›å»ºåŒæ ·å½¢çŠ¶çš„é›¶å‘é‡
    
    # è°ƒè¯•ä¿¡æ¯
    st.write(f"èƒŒæ™¯æ•°æ®å½¢çŠ¶: {background_data.shape}")
    st.write(f"å½“å‰æ ·æœ¬2Då½¢çŠ¶: {current_sample_2d.shape}")
    st.write(f"ç‰¹å¾æ•°é‡: {current_sample_2d.shape[1]}")
    
    # æµ‹è¯•æ¨¡å‹é¢„æµ‹å‡½æ•°
    try:
        test_pred = model_predict(background_data)
        st.write(f"èƒŒæ™¯æ•°æ®é¢„æµ‹æˆåŠŸ: {test_pred}")
        test_pred2 = model_predict(current_sample_2d)
        st.write(f"å½“å‰æ ·æœ¬é¢„æµ‹æˆåŠŸ: {test_pred2}")
    except Exception as e:
        st.error(f"æ¨¡å‹é¢„æµ‹æµ‹è¯•å¤±è´¥: {e}")
        st.stop()
    
    explainer = shap.KernelExplainer(model_predict, background_data)
    
    # è®¡ç®—å½“å‰è¾“å…¥æ ·æœ¬çš„SHAPå€¼
    shap_values = explainer.shap_values(current_sample_2d, nsamples=100)  # é™åˆ¶é‡‡æ ·æ•°é‡åŠ å¿«è®¡ç®—
    

    # ç”Ÿæˆ SHAP åŠ›å›¾
    # ç°åœ¨é¢„æµ‹å‡½æ•°ç›´æ¥è¿”å›å¤±ä»£å¿æ¦‚ç‡ï¼ŒSHAPå€¼å¤„ç†æ›´ç®€å•
    
    # å¤„ç†SHAPå€¼ - ç°åœ¨åº”è¯¥æ˜¯å•ä¸€è¾“å‡ºçš„å›å½’æ ¼å¼
    st.write(f"SHAPå€¼ç±»å‹: {type(shap_values)}")
    st.write(f"SHAPå€¼å½¢çŠ¶: {shap_values.shape if hasattr(shap_values, 'shape') else 'N/A'}")
    st.write(f"Expected value: {explainer.expected_value}")
    
    # æ­£ç¡®æå–SHAPå€¼
    if isinstance(shap_values, np.ndarray):
        if len(shap_values.shape) == 2:
            shap_values_for_class = shap_values[0]  # å–ç¬¬ä¸€è¡Œï¼ˆç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
        else:
            shap_values_for_class = shap_values
    else:
        shap_values_for_class = shap_values
    
    expected_value = explainer.expected_value
    if isinstance(expected_value, (list, np.ndarray)):
        expected_value = expected_value[0] if len(expected_value) > 0 else 0
    
    # ä¸ºäº†å¯è¯»æ€§ï¼Œåœ¨SHAPå›¾ä¸­æ˜¾ç¤ºåŸå§‹ç‰¹å¾å€¼
    features_df_original = pd.DataFrame([feature_values], columns=feature_ranges.keys())
    
    # ç”Ÿæˆæ ‡å‡†çš„ SHAP åŠ›å›¾
    try:
        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        expected_value = float(expected_value) if not isinstance(expected_value, (list, np.ndarray)) else expected_value[0] if len(expected_value) > 0 else 0.0
        
        # ç¡®ä¿SHAPå€¼æ˜¯numpyæ•°ç»„
        shap_values_array = np.array(shap_values_for_class).flatten()
        
        # è·å–ç‰¹å¾åç§°å’Œå€¼
        feature_names = list(feature_ranges.keys())
        feature_vals = features_df_original.iloc[0].values
        shap_vals = shap_values_array
        
        # ä¸»è¦è°ƒè¯•ä¿¡æ¯
        st.write(f"ä¸»åŠ›å›¾ - æå–çš„SHAPå€¼: {shap_vals}")
        st.write(f"ä¸»åŠ›å›¾ - SHAPå€¼æ€»å’Œ: {np.sum(shap_vals)}")
        st.write(f"ä¸»åŠ›å›¾ - åŸºå‡†å€¼: {expected_value}")
        st.write(f"ä¸»åŠ›å›¾ - é¢„æµ‹å€¼: {expected_value + np.sum(shap_vals)}")
        
        # æ–¹æ³•1ï¼šä½¿ç”¨SHAPåŸç”ŸåŠ›å›¾
        st.subheader("ğŸ“Š SHAP Force Plot (Original Style)")
        
        # å‡†å¤‡SHAPåŸç”ŸåŠ›å›¾æ•°æ®
        # éœ€è¦åˆ›å»ºshap.Explanationå¯¹è±¡
        explanation = shap.Explanation(
            values=shap_values_array,
            base_values=expected_value,
            data=feature_vals,
            feature_names=feature_names
        )
        
        # ç”ŸæˆSHAPåŠ›å›¾å¹¶ä¿å­˜ä¸ºHTML
        force_plot = shap.force_plot(
            base_value=expected_value,
            shap_values=shap_values_array,
            features=feature_vals,
            feature_names=feature_names,
            out_names="Decompensation Risk",
            matplotlib=False  # ä½¿ç”¨HTMLç‰ˆæœ¬
        )
        
        # å°†SHAPåŠ›å›¾ä¿å­˜ä¸ºHTMLæ–‡ä»¶å¹¶æ˜¾ç¤º
        with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False) as f:
            shap.save_html(f.name, force_plot)
            html_file = f.name
        
        # è¯»å–å¹¶æ˜¾ç¤ºHTML
        with open(html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        st.components.v1.html(html_content, height=300, scrolling=True)
        
        # æ–¹æ³•2ï¼šåˆ›å»ºè‡ªå®šä¹‰çš„ç»å…¸é£æ ¼åŠ›å›¾
        st.subheader("ğŸ“ˆ Custom SHAP Force Plot")
        
        # åˆ›å»ºæ ‡å‡†SHAPåŠ›å›¾æ ·å¼
        fig, ax = plt.subplots(figsize=(16, 4))
        
        # ç»˜åˆ¶æ ‡å‡†çš„æ°´å¹³ç€‘å¸ƒå›¾æ ·å¼
        y_pos = 0.5
        bar_height = 0.6
        
        # ä»åŸºå‡†å€¼å¼€å§‹ç´¯ç§¯ç»˜åˆ¶
        current_x = expected_value
        
        # æŒ‰ç…§SHAPå€¼ç»å¯¹å€¼æ’åºï¼Œç¡®ä¿é‡è¦ç‰¹å¾ä¼˜å…ˆæ˜¾ç¤º
        feature_importance = list(zip(feature_names, feature_vals, shap_vals))
        feature_importance.sort(key=lambda x: abs(x[2]), reverse=True)
        
        # åªæ˜¾ç¤ºå‰8ä¸ªæœ€é‡è¦çš„ç‰¹å¾ï¼Œé¿å…è¿‡äºæ‹¥æŒ¤
        top_features = feature_importance[:8]
        
        # ç»˜åˆ¶ç‰¹å¾è´¡çŒ®
        for i, (name, val, shap_val) in enumerate(top_features):
            # é€‰æ‹©é¢œè‰²ï¼šæ­£å€¼çº¢è‰²ï¼Œè´Ÿå€¼è“è‰²
            color = '#ff0051' if shap_val > 0 else '#008bfb'
            
            # è®¡ç®—æ¡å½¢çš„èµ·å§‹ä½ç½®
            start_x = current_x
            
            # ç»˜åˆ¶æ¡å½¢ï¼ˆä½¿ç”¨å¸¦ç¬¦å·çš„shap_valä½œä¸ºå®½åº¦ï¼‰
            rect = plt.Rectangle((start_x, y_pos - bar_height/2), 
                               shap_val, bar_height,
                               facecolor=color, alpha=0.8, 
                               edgecolor='white', linewidth=2)
            ax.add_patch(rect)
            
            # æ·»åŠ ç‰¹å¾æ ‡ç­¾ï¼ˆåœ¨æ¡å½¢ä¸Šæ–¹ï¼‰
            mid_x = start_x + shap_val/2
            ax.text(mid_x, y_pos + bar_height/2 + 0.05, 
                   f'{name} = {val:.2f}', 
                   ha='center', va='bottom', fontsize=9, 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9, edgecolor=color))
            
            # æ·»åŠ SHAPå€¼æ ‡ç­¾ï¼ˆåœ¨æ¡å½¢ä¸­å¤®ï¼‰
            ax.text(mid_x, y_pos, 
                   f'{shap_val:.3f}', 
                   ha='center', va='center', fontsize=10, 
                   color='white', fontweight='bold')
            
            # æ›´æ–°ç´¯ç§¯ä½ç½®
            current_x += shap_val
        
        # æ·»åŠ é¡¶éƒ¨çš„higher/loweræ ‡è¯†ç®­å¤´
        ax.annotate('higher', xy=(0.02, 0.85), xycoords='axes fraction',
                   fontsize=14, color='#ff0051', fontweight='bold', ha='left',
                   arrowprops=dict(arrowstyle='->', color='#ff0051', lw=2))
        ax.annotate('lower', xy=(0.98, 0.85), xycoords='axes fraction',
                   fontsize=14, color='#008bfb', fontweight='bold', ha='right',
                   arrowprops=dict(arrowstyle='<-', color='#008bfb', lw=2))
        
        # æ·»åŠ å‚ç›´çº¿æ ‡è®°åŸºå‡†å€¼å’Œæœ€ç»ˆå€¼
        ax.axvline(x=expected_value, color='gray', linestyle='--', alpha=0.8, linewidth=3)
        ax.axvline(x=current_x, color='black', linestyle='-', alpha=0.9, linewidth=3)
        
        # æ·»åŠ base valueæ ‡è¯†
        ax.text(expected_value, y_pos - bar_height/2 - 0.15, 'base value', 
               ha='center', va='top', fontsize=12, color='gray', fontweight='bold',
               bbox=dict(boxstyle="round,pad=0.2", facecolor='lightgray', alpha=0.8))
        
        # æ·»åŠ f(x)é¢„æµ‹å€¼æ ‡è¯†
        actual_decompensation_prob = predicted_proba[1] * 100
        ax.text(current_x, y_pos + bar_height/2 + 0.2, f'f(x)\n{actual_decompensation_prob:.2f}%', 
               ha='center', va='bottom', fontsize=14, fontweight='bold',
               bbox=dict(boxstyle="round,pad=0.4", facecolor='yellow', alpha=0.9, edgecolor='orange'))
        
        # è®¾ç½®å›¾è¡¨å±æ€§ï¼Œç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½èƒ½æ˜¾ç¤º
        x_range = abs(current_x - expected_value)
        margin = max(0.02, x_range * 0.1)  # åŠ¨æ€è¾¹è·
        x_min = min(expected_value, current_x) - margin
        x_max = max(expected_value, current_x) + margin
        ax.set_xlim(x_min, x_max)
        ax.set_ylim(-0.1, 1.2)
        
        # ç§»é™¤yè½´åˆ»åº¦å’Œæ ‡ç­¾
        ax.set_yticks([])
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_visible(False)
        
        # è®¾ç½®xè½´
        ax.set_xlabel('Model Output Value', fontsize=12)
        ax.grid(True, alpha=0.3, axis='x')
        
        # è®¾ç½®æ ‡é¢˜
        ax.set_title(f'SHAP Force Plot for Decompensation Risk (Probability: {probability:.2f}%)', 
                    fontsize=14, fontweight='bold', pad=20)
        
        plt.tight_layout()
        plt.savefig("shap_force_plot.png", bbox_inches='tight', dpi=300, facecolor='white')
        plt.close()
        st.image("shap_force_plot.png")
        
    except Exception as e:
        st.error(f"SHAP force plot generation failed: {str(e)}")
        st.info("Using backup SHAP feature importance chart")
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šç”ŸæˆSHAPç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
        try:
            plt.figure(figsize=(10, 6))
            
            # è·å–ç‰¹å¾åç§°å’ŒSHAPå€¼
            shap_vals = np.array(shap_values_for_class).flatten()
            
            # æœ€ç»ˆè°ƒè¯•ä¿¡æ¯
            st.write(f"æå–çš„SHAPå€¼: {shap_vals}")
            st.write(f"SHAPå€¼æ€»å’Œ: {np.sum(shap_vals)}")
            st.write(f"åŸºå‡†å€¼: {expected_value}")
            st.write(f"é¢„æµ‹å€¼: {expected_value + np.sum(shap_vals)}")
            
            # ä½¿ç”¨ç‰¹å¾åç§°
            feature_names = list(feature_ranges.keys())
            
            # åˆ›å»ºç‰¹å¾é‡è¦æ€§æ’åº
            importance_data = list(zip(feature_names, shap_vals))
            importance_data.sort(key=lambda x: abs(x[1]), reverse=True)
            
            # ç»˜åˆ¶æ¡å½¢å›¾
            features, values = zip(*importance_data)
            colors = ['red' if v < 0 else 'blue' for v in values]
            
            plt.barh(range(len(features)), values, color=colors, alpha=0.7)
            plt.yticks(range(len(features)), features)
            plt.xlabel('SHAP Value (Feature Impact on Prediction)')
            plt.title('Feature Impact on Prediction Results (SHAP Analysis)')
            plt.grid(axis='x', alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, v in enumerate(values):
                plt.text(v + (0.01 if v >= 0 else -0.01), i, f'{v:.3f}', 
                        va='center', ha='left' if v >= 0 else 'right')
            
            plt.tight_layout()
            plt.savefig("shap_bar_plot.png", bbox_inches='tight', dpi=300)
            plt.close()
            st.image("shap_bar_plot.png")
            
        except Exception as e2:
            st.error(f"Backup SHAP chart generation also failed: {str(e2)}")
            st.write("SHAPå€¼:", shap_values_for_class)
    
    # # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    # import os
    # import time
    # time.sleep(1)  # ç­‰å¾…å›¾ç‰‡æ˜¾ç¤ºå®Œæˆ
    # try:
    #     os.remove("shap_force_plot.png")
    # except FileNotFoundError:
    #     pass



